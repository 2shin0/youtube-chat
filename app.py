# 3data/data_analysis.pyì— ê¸°ëŠ¥ ì¶”ê°€ëœ ë²„ì „
# 1. gemini_api_key í™˜ê²½ë³€ìˆ˜ ì„¤ì • í•„ìš”
# 2. mcp_server_url í™˜ê²½ë³€ìˆ˜ ì„¤ì • í•„ìš”
# 3. ì„¸ì…˜ ê¸°ë°˜ ëŒ€í™” ê¸°ë¡ ê´€ë¦¬ ì¶”ê°€ë¨

# ë°°í¬ë¥¼ ìœ„í•´ íŒŒì¼ëª…ì„ app.pyë¡œ ë³€ê²½



# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°
import streamlit as st
import google.generativeai as genai
import time
from fastmcp import Client
from fastmcp.client.auth import BearerAuth
import json
import asyncio
from typing import List, Dict, Any
from google import genai


# --- í™˜ê²½ë³€ìˆ˜ ì„¤ì • ---
token = st.secrets.oauth.token
MCP_SERVER_URL = st.secrets.api.mcp_server_url  
api_key = st.secrets.gemini_api_key



# --- FastMCP ì„œë²„ ì„¤ì • ---
mcp_client = Client(
    MCP_SERVER_URL,
    auth=BearerAuth(token)
)

gemini_client = genai.Client(api_key=api_key)



# --- FastMCP Tool í˜¸ì¶œ í•¨ìˆ˜ ---
async def async_tool_call(tool_name: str, tool_args: Dict[str, Any]) -> Any:
    """FastMCP í´ë¼ì´ì–¸íŠ¸ë¥¼ ì—°ê²°í•˜ê³  íŠ¹ì • íˆ´ì„ í˜¸ì¶œí•©ë‹ˆë‹¤."""
    # mcp_clientëŠ” ì „ì—­ ê°ì²´ì´ë¯€ë¡œ ì¸ìë¡œ ì „ë‹¬í•˜ì§€ ì•Šê³  ë°”ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.
    async with mcp_client:
        result = await mcp_client.call_tool(tool_name, tool_args)
        return result.data



# --- ëŒ€í™” ê¸°ë¡ ê´€ë¦¬ ë¡œì§ ---

# ëŒ€í™” ê¸°ë¡ì„ ì €ì¥í•  ê³µê°„ ë§Œë“¤ê¸° (session_state ì‚¬ìš©)
if "chat_sessions" not in st.session_state:
    # {ì„¸ì…˜ID: {"title": "ì œëª©", "messages": [...]}}
    st.session_state.chat_sessions = {}
    
if "current_session_id" not in st.session_state:
    st.session_state.current_session_id = None
    
def new_chat_session():
    """ìƒˆë¡œìš´ ì±„íŒ… ì„¸ì…˜ì„ ìƒì„±í•˜ê³  í™œì„±í™”í•©ë‹ˆë‹¤."""
    # ê³ ìœ í•œ ì„¸ì…˜ ID ìƒì„±
    new_id = f"chat_{int(time.time() * 1000)}" 
    st.session_state.chat_sessions[new_id] = {
        "title": "ìƒˆ ëŒ€í™”", 
        "messages": []
    }
    st.session_state.current_session_id = new_id

# ì•± ì‹œì‘ ì‹œ ë˜ëŠ” ì„¸ì…˜ì´ ì—†ì„ ê²½ìš° ìƒˆ ì„¸ì…˜ ìƒì„±
if st.session_state.current_session_id is None or st.session_state.current_session_id not in st.session_state.chat_sessions:
    new_chat_session()
    
# í˜„ì¬ í™œì„± ì„¸ì…˜ì˜ ë©”ì‹œì§€ ëª©ë¡ì„ ì§§ê²Œ ì°¸ì¡°
current_session = st.session_state.chat_sessions[st.session_state.current_session_id]
current_messages = current_session["messages"]



# --- ì‚¬ì´ë“œë°” ---

# ì‚¬ì´ë“œë°” - ì„¸ì…˜ ê´€ë¦¬
st.sidebar.title("ğŸ’¬ ëŒ€í™” ê¸°ë¡")
if st.sidebar.button("â• ìƒˆ ëŒ€í™” ì‹œì‘"):
    new_chat_session()
    st.rerun()

st.sidebar.caption("âš ï¸ ì´ ê¸°ë¡ì€ ë¸Œë¼ìš°ì €ë¥¼ ë‹«ìœ¼ë©´ ì‚¬ë¼ì§‘ë‹ˆë‹¤.")

# ëŒ€í™” ëª©ë¡ í‘œì‹œ ë° ì„ íƒ
for session_id, session_data in st.session_state.chat_sessions.items():
    if st.sidebar.button(
        session_data["title"], 
        key=session_id,
        use_container_width=True,
        # í˜„ì¬ ì„¸ì…˜ ê°•ì¡° í‘œì‹œ (ì„ íƒ ì‚¬í•­)
        # help="í´ë¦­í•˜ì—¬ ëŒ€í™”ë¡œ ì´ë™" 
    ):
        st.session_state.current_session_id = session_id
        st.rerun()



# --- ë¹„ë™ê¸° ì±—ë´‡ ì‘ë‹µ ìƒì„± í•¨ìˆ˜ ---
async def generate_chat_response(messages: List[Dict[str, str]], system_prompt: str, message_placeholder):
    """
    ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ê¸°ë°˜ìœ¼ë¡œ Gemini APIì™€ FastMCP Tool Callingì„ í†µí•©í•˜ì—¬ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    
    # 1. Gemini APIì— ì „ë‹¬í•  ëŒ€í™” ê¸°ë¡ í¬ë§·íŒ…
    # FastMCP Tool Callingì„ í¬í•¨í•œ ë³µì¡í•œ ëŒ€í™”ëŠ” generate_contentì— ì „ì²´ historyë¥¼ ì „ë‹¬í•˜ëŠ” ê²ƒì´ ì•ˆì •ì ì…ë‹ˆë‹¤.
    # ì—­í• ì€ 'user'ì™€ 'model' (ì´ì „ AI ì‘ë‹µ), Tool ê²°ê³¼ëŠ” 'tool'ì…ë‹ˆë‹¤.
    full_history = []
    for m in messages:
        # Gemini APIëŠ” 'assistant' ëŒ€ì‹  'model' ì—­í• ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
        role = "model" if m["role"] == "assistant" else m["role"]
        full_history.append(genai.types.Content(role=role, parts=[genai.types.Part.from_text(m["content"])]))
    
    # Tool Calling ë°˜ë³µ
    response = None
    
    # ì´ˆê¸° ìš”ì²­ (ì‚¬ìš©ì ë©”ì‹œì§€ í¬í•¨)
    response = gemini_client.models.generate_content(
        model="gemini-2.5-pro",
        contents=full_history,
        config=genai.types.GenerateContentConfig(
            system_instruction=system_prompt,
            temperature=0,
            tools=[mcp_client.session] # FastMCP Clientì˜ ì„¸ì…˜ì„ Tool ì •ì˜ë¡œ ì „ë‹¬
        )
    )
    
    while response.function_calls:
        tool_results = []
        
        # ì‘ë‹µ ìš”ì•½ í‘œì‹œ (ì‚¬ìš©ìì—ê²Œ ì‘ì—… ì¤‘ì„ì„ ì•Œë¦¼)
        message_placeholder.write(f"ğŸ” AIê°€ í•„ìš”í•œ ë°ì´í„°ë¥¼ **MCP ì„œë²„**ë¥¼ í†µí•´ ìˆ˜ì§‘ ì¤‘ì…ë‹ˆë‹¤ ({len(response.function_calls)}ê°œ ìš”ì²­)...")
        
        # Tool Call ê²°ê³¼ë¥¼ historyì— ì¶”ê°€ (ëª¨ë¸ì´ ìš”ì²­í–ˆë˜ ë‚´ìš©)
        full_history.append(response.candidates[0].content)

        for call in response.function_calls:
            tool_name = call.name
            tool_args = dict(call.args)
            
            try:
                # CRITICAL: FastMCPëŠ” ë¹„ë™ê¸°ì´ë¯€ë¡œ await/asyncio.runìœ¼ë¡œ ì‹¤í–‰
                tool_output = await async_tool_call(tool_name, tool_args)
                
                # ê²°ê³¼ë¥¼ JSON ë¬¸ìì—´ë¡œ ë³€í™˜ (ëª¨ë¸ì— ì „ë‹¬í•˜ê¸° ìœ„í•¨)
                if not isinstance(tool_output, (str, bytes)):
                    # Toolì˜ ë°˜í™˜ ê°’ì´ ë¬¸ìì—´ì´ ì•„ë‹Œ ê²½ìš° JSONìœ¼ë¡œ ë³€í™˜
                    tool_output = json.dumps(tool_output, ensure_ascii=False, indent=2)
                    
                message_placeholder.write(
                    f"âœ… Tool í˜¸ì¶œ: `{tool_name}` ì‹¤í–‰ ì™„ë£Œ."
                )
                
            except Exception as e:
                tool_output = f"Tool ì‹¤í–‰ ì˜¤ë¥˜ ({tool_name}): {e}"
                message_placeholder.write(
                    f"âŒ Tool í˜¸ì¶œ: `{tool_name}` ì‹¤í–‰ ì‹¤íŒ¨. ì˜¤ë¥˜: {tool_output}"
                )

            # Tool ì‹¤í–‰ ê²°ê³¼ë¥¼ í¬í•¨í•˜ì—¬ historyì— ì¶”ê°€
            tool_results.append(
                genai.types.Part.from_function_response(
                    name=tool_name, 
                    response=tool_output
                )
            )
        
        # Tool ê²°ê³¼ ë©”ì‹œì§€ (ì—­í•  'tool')ë¥¼ historyì— ì¶”ê°€
        full_history.append(genai.types.Content(role="tool", parts=tool_results))
        
        # Tool ì‹¤í–‰ ê²°ê³¼ë¥¼ í¬í•¨í•˜ì—¬ ë‹¤ì‹œ Geminiì— ìš”ì²­
        response = gemini_client.models.generate_content(
            model="gemini-2.5-pro",
            contents=full_history,
            config=genai.types.GenerateContentConfig(
                system_instruction=system_prompt,
                temperature=0,
                tools=[mcp_client.session]
            )
        )
        
    # ìµœì¢… ì‘ë‹µ ì¶”ì¶œ ë° í‘œì‹œ
    full_response = response.text
    message_placeholder.write(full_response)
    return full_response



# --- ë©”ì¸ ì±—ë´‡ ì¸í„°í˜ì´ìŠ¤ ---

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ìœ íŠœë¸Œ ë°ì´í„° ë¶„ì„ ì±—ë´‡", page_icon="ğŸ“Š")

# ì œëª© í‘œì‹œ
st.title("ğŸ“Š ìœ íŠœë¸Œ ë°ì´í„° ë¶„ì„ ì±—ë´‡")
st.write(f"**{current_session['title']}**")

# ì´ì „ ëŒ€í™” ë‚´ìš© í™”ë©´ì— í‘œì‹œí•˜ê¸°
for message in current_messages:
    with st.chat_message(message["role"]):
        st.write(message["content"])

# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì •ì˜
system_prompt = """
        ë‹¹ì‹ ì€ ìœ íŠœë¸Œ ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
        ë‹¹ì‹ ì˜ ì—­í• ì€ YouTube ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ì¸ì‚¬ì´íŠ¸ë¥¼ ë„ì¶œí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

        ë°ì´í„°ëŠ” ë‹¤ìŒ 4ê°€ì§€ ì¶œì²˜ ì¤‘ í•˜ë‚˜ ë˜ëŠ” ì—¬ëŸ¬ ê°œê°€ í¬í•¨ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤:
        1. get_youtube_transcript â†’ ì˜ìƒ ìë§‰ ì „ì²´ í…ìŠ¤íŠ¸
        2. search_youtube_videos â†’ ê²€ìƒ‰ëœ ì˜ìƒ ë¦¬ìŠ¤íŠ¸ (ì œëª©, ì¡°íšŒìˆ˜, ì±„ë„ëª…, ì¢‹ì•„ìš” ìˆ˜ ë“±)
        3. get_channel_info â†’ ì±„ë„ ê¸°ë³¸ ì •ë³´ ë° ìµœê·¼ ì˜ìƒ
        4. get_youtube_comments â†’ ëŒ“ê¸€ ë‚´ìš©, ì¢‹ì•„ìš” ìˆ˜, ì‘ì„±ì ë“±

        ---

        ### ë¶„ì„ ë‹¨ê³„
        1. ë°ì´í„° íŒŒì•…: ì–´ë–¤ MCP Toolì˜ ê²°ê³¼ì¸ì§€ ì‹ë³„í•˜ê³ , í•„ìš”ì‹œ ì—¬ëŸ¬ ë„êµ¬ì˜ ë°ì´í„°ë¥¼ ê²°í•©í•´ ë¬¸ë§¥ì ìœ¼ë¡œ ì´í•´í•©ë‹ˆë‹¤.
        2. ìš”ì•½ / ê°œìš” ìƒì„±: ìë§‰ì€ í•µì‹¬ ì£¼ì œë¥¼, ì˜ìƒ ë¦¬ìŠ¤íŠ¸ëŠ” íŠ¹ì§•ì„, ëŒ“ê¸€ì€ ê°ì„±/í‚¤ì›Œë“œë¥¼ ìš”ì•½í•©ë‹ˆë‹¤.
        3. ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ: ì˜ìƒì˜ í•µì‹¬ ë©”ì‹œì§€, íƒ€ê²Ÿ ì‹œì²­ì, ì±„ë„ì˜ ì„±ì¥ ë°©í–¥ ë“±ì„ ë¶„ì„í•©ë‹ˆë‹¤.
        4. ìµœì¢… ì¶œë ¥ í˜•íƒœ: ë¶„ì„ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ êµ¬ì²´ì ì¸ ìœ íŠœë¸Œ ë°ì´í„° ë¶„ì„ ë³´ê³ ì„œë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.

        ---

        ### ì£¼ì˜ì‚¬í•­
        - ë°ì´í„°ê°€ ì¼ë¶€ ëˆ„ë½ë˜ì—ˆì„ ê²½ìš°, ê°€ëŠ¥í•œ ì •ë³´ë§Œ í™œìš©í•˜ê³  ë°ì´í„° ë¶€ì¡±ì´ë¼ê³  ëª…ì‹œí•©ë‹ˆë‹¤.
        - ëŒ“ê¸€ ë¶„ì„ ì‹œ ìš•ì„¤, ì¸ì‹ ê³µê²© ë“±ì€ ì œì™¸í•˜ê³  **ì£¼ìš” ì˜ê²¬ì˜ ê²½í–¥ì„±**ë§Œ ë°˜ì˜í•©ë‹ˆë‹¤.
        - ì–¸ì–´ëŠ” ì…ë ¥ ë°ì´í„°ì˜ ì–¸ì–´(í•œêµ­ì–´/ì˜ì–´ ë“±)ì— ë§ê²Œ ë™ì¼í•˜ê²Œ ìœ ì§€í•©ë‹ˆë‹¤.
        """

# ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
user_input = st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”...")

# ì‚¬ìš©ìê°€ ë©”ì‹œì§€ë¥¼ ì…ë ¥í–ˆì„ ë•Œ
if user_input:          
    # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ í˜„ì¬ ì„¸ì…˜ì˜ ê¸°ë¡ì— ì¶”ê°€
    current_messages.append({"role": "user", "content": user_input})

    # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ í™”ë©´ì— í‘œì‹œ
    with st.chat_message("user"):
        st.write(user_input)

    # AIì˜ ì‘ë‹µì„ í™”ë©´ì— í‘œì‹œí•  ì˜ì—­
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        
        # CRITICAL FIX: ë¹„ë™ê¸° í•¨ìˆ˜ë¥¼ ë™ê¸° Streamlit íë¦„ì—ì„œ ì‹¤í–‰
        try:
            full_response = asyncio.run(
                generate_chat_response(
                    current_messages, 
                    system_prompt, 
                    message_placeholder
                )
            )
            
            # AI ì‘ë‹µì„ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
            current_messages.append({"role": "assistant", "content": full_response})

        except Exception as e:
            error_message = f"ì±—ë´‡ ì‹¤í–‰ ì¤‘ ì¹˜ëª…ì ì¸ ì˜¤ë¥˜ ë°œìƒ: {e}"
            message_placeholder.error(error_message)
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ë§ˆì§€ë§‰ ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ê¸°ë¡ì—ì„œ ì œê±° (ì¬ì‹œë„ ìš©ì´)
            current_messages.pop()
            print(error_message)

    # ëŒ€í™” ì œëª© ìë™ ì„¤ì • (ì²« ì§ˆë¬¸ì— ëŒ€í•´)
    if current_session["title"] == "ìƒˆ ëŒ€í™”":
        current_session["title"] = user_input[:30] + "..." if len(user_input) > 30 else user_input
        st.rerun()













