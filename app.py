# 3data/data_analysis.py ê¸°ë°˜ ì½”ë“œ
# Streamlit Cloudì—ì„œ Gemini API Key, MCP URL í™˜ê²½ë³€ìˆ˜ ì„¤ì • í•„ìš”
# Streamlit ì•±ìœ¼ë¡œ FastMCP Tool Calling í†µí•©
# ë¹„ë™ê¸° ë°©ì‹ìœ¼ë¡œ(ì„œë²„ì—ì„œ ë°ì´í„° ë°›ì•„ì˜¤ëŠ” ë™ì•ˆ UI ë©ˆì¶”ì§€ ì•Šê³  ê³„ì† ëŒì•„ê°€ë„ë¡) Gemini APIì™€ MCP Tool í˜¸ì¶œ ì—°ë™


# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°
# 3data/data_analysis_streamlit_async.py
import streamlit as st
import time
import asyncio
import json
from typing import List, Dict, Any
from fastmcp import Client
from google import genai

# --- í™˜ê²½ë³€ìˆ˜ ì„¤ì • ---
MCP_SERVER_URL = st.secrets.api.mcp_server_url
api_key = st.secrets.gemini_api_key

# --- FastMCP, Gemini í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ---
mcp_client = Client(MCP_SERVER_URL)
gemini_client = genai.Client(api_key=api_key)

# --- ì„¸ì…˜ ë° ë©”ì‹œì§€ ì´ˆê¸°í™” ---
if "chat_sessions" not in st.session_state:
    st.session_state.chat_sessions = {}

if "current_session_id" not in st.session_state:
    st.session_state.current_session_id = None

def new_chat_session():
    session_id = f"chat_{int(time.time()*1000)}"
    st.session_state.chat_sessions[session_id] = {"title": "ìƒˆ ëŒ€í™”", "messages": []}
    st.session_state.current_session_id = session_id

if st.session_state.current_session_id is None or st.session_state.current_session_id not in st.session_state.chat_sessions:
    new_chat_session()

current_session = st.session_state.chat_sessions[st.session_state.current_session_id]
current_messages = current_session["messages"]

# --- FastMCP Tool í˜¸ì¶œ ---
async def async_tool_call(client: Client, tool_name: str, tool_args: Dict[str, Any]) -> Any:
    result = await client.call_tool(tool_name, tool_args)
    return result.data

# --- ë¹„ë™ê¸° ì±—ë´‡ ì‘ë‹µ ìƒì„± ---
async def generate_chat_response_async(messages: List[Dict[str, str]], system_prompt: str, placeholder):
    # messages ê¸°ë°˜ full_history ëˆ„ì 
    full_history = []
    for m in messages:
        role = "model" if m["role"] == "assistant" else m["role"]
        full_history.append(genai.types.Content(role=role, parts=[genai.types.Part.from_text(m["content"])]))

    async with mcp_client:
        response = await gemini_client.aio.models.generate_content(
            model="gemini-2.5-pro",
            contents=full_history,
            config=genai.types.GenerateContentConfig(
                system_instruction=system_prompt,
                temperature=0,
                tools=[mcp_client.session]
            )
        )

        # Tool í˜¸ì¶œ ë£¨í”„
        while getattr(response, "function_calls", None):
            tool_results = []
            placeholder.write(f"ğŸ” MCP Tool í˜¸ì¶œ ì¤‘ ({len(response.function_calls)}ê°œ) ...")

            for call in response.function_calls:
                tool_name = call.name
                tool_args = dict(call.args)
                try:
                    tool_output = await async_tool_call(mcp_client, tool_name, tool_args)
                    if not isinstance(tool_output, (str, bytes)):
                        tool_output = json.dumps(tool_output, ensure_ascii=False, indent=2)
                    placeholder.write(f"âœ… Tool `{tool_name}` ì™„ë£Œ")
                except Exception as e:
                    tool_output = f"Tool ì˜¤ë¥˜ ({tool_name}): {e}"
                    placeholder.write(f"âŒ Tool `{tool_name}` ì‹¤íŒ¨: {tool_output}")

                # Tool ê²°ê³¼ ë©”ì‹œì§€ë¡œ ê¸°ë¡
                tool_content = genai.types.Content(
                    role="tool",
                    parts=[genai.types.Part.from_function_response(name=tool_name, response=tool_output)]
                )
                full_history.append(tool_content)
                current_messages.append({"role": "assistant", "content": tool_output})

            # Tool ê²°ê³¼ë¥¼ ë°˜ì˜í•´ ë‹¤ì‹œ GPT ì‘ë‹µ ìƒì„±
            response = await gemini_client.aio.models.generate_content(
                model="gemini-2.5-pro",
                contents=full_history,
                config=genai.types.GenerateContentConfig(
                    system_instruction=system_prompt,
                    temperature=0,
                    tools=[mcp_client.session]
                )
            )

    # ìµœì¢… GPT ì‘ë‹µ
    placeholder.write(response.text)
    current_messages.append({"role": "assistant", "content": response.text})
    return response.text

# --- Streamlitìš© async ì‹¤í–‰ ë˜í¼ ---
def run_async(coro):
    try:
        loop = asyncio.get_running_loop()
        return asyncio.ensure_future(coro)
    except RuntimeError:
        return asyncio.run(coro)

def generate_chat_response(messages: List[Dict[str, str]], system_prompt: str, placeholder):
    return run_async(generate_chat_response_async(messages, system_prompt, placeholder))

# --- ì‚¬ì´ë“œë°” ---
st.sidebar.title("ğŸ’¬ ëŒ€í™” ê¸°ë¡")
if st.sidebar.button("â• ìƒˆ ëŒ€í™” ì‹œì‘"):
    new_chat_session()
    st.rerun()

for sid, sdata in st.session_state.chat_sessions.items():
    if st.sidebar.button(sdata["title"], key=sid, use_container_width=True):
        st.session_state.current_session_id = sid
        st.rerun()

st.sidebar.caption("âš ï¸ ì´ ê¸°ë¡ì€ ë¸Œë¼ìš°ì €ë¥¼ ë‹«ìœ¼ë©´ ì‚¬ë¼ì§‘ë‹ˆë‹¤.")

# --- ë©”ì¸ í˜ì´ì§€ ---
st.set_page_config(page_title="ìœ íŠœë¸Œ ë°ì´í„° ë¶„ì„ ì±—ë´‡", page_icon="ğŸ“Š")
st.title("ğŸ“Š ìœ íŠœë¸Œ ë°ì´í„° ë¶„ì„ ì±—ë´‡")
st.write(f"**{current_session['title']}**")

for message in current_messages:
    with st.chat_message(message["role"]):
        st.write(message["content"])

system_prompt = """ë‹¹ì‹ ì€ ìœ íŠœë¸Œ ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ... (ì´ì „ prompt ê·¸ëŒ€ë¡œ)"""

user_input = st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”...")
if user_input:
    current_messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.write(user_input)
    with st.chat_message("assistant"):
        placeholder = st.empty()
        full_response = generate_chat_response(current_messages, system_prompt, placeholder)
        if asyncio.isfuture(full_response):
            full_response = asyncio.run(full_response)
    if current_session["title"] == "ìƒˆ ëŒ€í™”":
        current_session["title"] = user_input[:30] + "..." if len(user_input) > 30 else user_input
        st.rerun()
